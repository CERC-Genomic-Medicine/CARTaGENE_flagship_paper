{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183dfd16-2845-407a-9dce-821ddd6725d7",
   "metadata": {},
   "source": [
    "# Visualization of CARTaGENE population structure\n",
    "\n",
    "To run this notebook specifically as in the manuscript:\n",
    "* load ipython/3.8\n",
    "* load scipy-stack/2020b\n",
    "* shut down the kernel\n",
    "* select the new kernel (should be python 3.8.*)\n",
    "\n",
    "These are all relative to my directories. Where you see `...`, insert your own paths.\n",
    "\n",
    "For the entire pipeline, you will need to do the following:\n",
    "\n",
    "* Generate the principal components after having filtered for LD and HLA. You can use PLINK and/or flashPCA (the latter outputs an estimated variance explained).\n",
    "* Generate 2D or 3D UMAP embeddings (for visualization); 2D embeddings are good for static images, 3D are good for interactive exploration with `plotly`. These generally have `n_neighbors` set between 10 and 25. Setting this very low (e.g. 3-5) can result in small clusters of related individuals. `min_dist` is set between 0.3 and 0.5 to allow for better visualizations. I vary the number of input PCs to see if there are any interesting differences or patterns with more or less data. \n",
    "* Generate UMAP embeddings in 3 or higher dimensions for density-based clustering using HDBSCAN. These UMAP embeddings should have `min_dist` set very low (equal or close to 0).\n",
    "* Generate clusters using HDBSCAN$(\\hat{\\epsilon})$. Setting the $\\hat{\\epsilon}$ parameter (split-merger threshold) at 0.5 works reasonably well for biobank data. These parameter combinations tend to highlight both very local and global levels of population structure (e.g. structure within Quebec as well as continental/sub-continental population structure).\n",
    "* Colour the 2D UMAP embeddings using the HDBSCAN clusters.\n",
    "\n",
    "The code here focuses on generating visualizations. My strategy has been to generate many embeddings and clusterings using a grid search. For visualization I find using 10-25 PCs is useful. For which clustering to use, I usually choose one that has (1) many/the most clusters; and (2) every individual or almost every individual belongs to a cluster. I recommend using a range of PCs (there is pretty much always signal in higher-order PCs; see the paper on topological stratificaton for details). For the plots, I recommend removing tick-marks from axes as UMAP distances are not interpretable. I also usually plot the largest clusters first to make sure I don't smother smaller groups.\n",
    "\n",
    "I put together the final figures using external software but you could probably do it if you're clever enough with some combination of matplotlib, ggplot2, and imagemagick.\n",
    "\n",
    "For a fuller exploration of UMAP/HDBSCAN for population genetics, see the following manuscripts:\n",
    "* [Diaz-Papkovich, Alex, et al. \"UMAP reveals cryptic population structure and phenotype heterogeneity in large genomic cohorts.\" PLoS genetics 15.11 (2019): e1008432.](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1008432)\n",
    "* [Diaz-Papkovich, Alex, et al. \"Topological stratification of continuous genetic variation in large biobanks.\" bioRxiv (2023): 2023-07.](https://www.biorxiv.org/content/10.1101/2023.07.06.548007.abstract)\n",
    "\n",
    "For more general scripts for UMAP and clustering see https://github.com/diazale/topstrat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29978c31-6b2c-46da-910f-8fbf0f4598e4",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "Need to install word cloud and font packages. Once installed, restart the kernel. It might take a few attemps to install these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b0dc8-6155-4ff5-a0da-71aea80ce614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud\n",
    "#!pip install fonttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c81e3-7227-4260-ba75-059ddf331487",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a371bd-bd73-4045-a06e-d29931cb8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image # For displaying documentation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f1556-a14f-49e0-8b98-e933efdace0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = \"/hla_removed_ld_thinned_0.1\" # Sub-directories for specific runs. I used a run with LD thinning and HLA removed.\n",
    "\n",
    "# Key directories and files\n",
    "# You will also have to import various files of questionnaire data, however these directories have already changed since I wrote this code\n",
    "cluster_dir = \".../cartagene/hdbscan_clusters\" + subdir # Cluster locations\n",
    "viz_dir = \".../cartagene/projections_viz\" + subdir # 2D and 3D UMAP plots for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202564de-61ba-4d8e-a958-789da44178c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file names generated by my UMAP and HDBSCAN scripts contain their parameters.\n",
    "# This code extracts the parameters in the file names.\n",
    "def extract_parameters(fname_):\n",
    "    # Input: Clustering file name\n",
    "    # Output: Parameters used to generate the clustering\n",
    "    \n",
    "    # Variables:\n",
    "    # Minimum points\n",
    "    # Epsilon\n",
    "    # PCs\n",
    "    # NC\n",
    "    # NN\n",
    "    # MD\n",
    "    mp_ = int(fname_.split(\"_min\")[1].split(\"_\")[0])\n",
    "    eps_ = float(fname_.split(\"_EPS\")[1].split(\"_\")[0])\n",
    "    pcs_ = int(fname_.split(\"_PC\")[1].split(\"_\")[0])\n",
    "    nc_ = int(fname_.split(\"_NC\")[1].split(\"_\")[0])\n",
    "    nn_ = int(fname_.split(\"_NN\")[1].split(\"_\")[0])\n",
    "    md_ = float(fname_.split(\"_MD\")[1].split(\"_\")[0])\n",
    "    \n",
    "    return mp_, eps_, pcs_, nc_, nn_, md_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e12ee-e3d9-4667-a62f-d1c84a5bffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the clusterings and create a data frame to store their details and parameterizations\n",
    "# Using this we can look at all of the clusterings and see (1) how many clusters there are; and (2) how many individuals are not in a cluster\n",
    "cluster_properties = list()\n",
    "\n",
    "for c in os.listdir(cluster_dir):\n",
    "    if os.path.isfile(os.path.join(cluster_dir, c)):\n",
    "        cl = np.loadtxt(os.path.join(cluster_dir,c))\n",
    "        num_unclustered = np.sum(cl==-1)\n",
    "        num_clusters = len(set(cl))\n",
    "        mp, e, p, nc, nn, md = extract_parameters(c)\n",
    "        cluster_properties.append([mp,e,p,nc,nn,md,num_unclustered,num_clusters,c])\n",
    "        \n",
    "cluster_properties_df = pd.DataFrame(cluster_properties,\n",
    "                                     columns=[\"min_points\",\"eps\",\"pcs\",\"nc\",\"nn\",\"md\",\"unclustered\",\"clusters\",\"name\"])\n",
    "\n",
    "# Write to disk\n",
    "cluster_properties_df.to_csv(out_dir + \"/cluster_properties.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5be48-fab5-4059-a4f2-9df92c577a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the variables I used to generate word clouds\n",
    "# I selected these to try and understand the demographic histories underlying the population structure in our genetic data\n",
    "# They are the collection region, country of birth, province of birth (if born in Canada), and selected ethnicity variables\n",
    "# For brevity I have excluded a series of splits and mergers that are necessary to generate the full data set (geno_df_analysis)\n",
    "# This should be straightforward (if somewhat tedious) to generate using various split/merge commands\n",
    "variables_of_interest = [\n",
    "\"Cregion\",\n",
    "\"PROVINCE_BIRTH\",\n",
    "\"COUNTRY_BIRTH\",\n",
    "\"COUNTRY_BIRTH_OTHER\",\n",
    "\"ETHNICITY_ME\",\n",
    "\"ethnic_fr\",\n",
    "\"ETHNIC_FR_CB\",\n",
    "\"ethnicity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f169d8-1e85-49f8-9f3e-c4f7df82e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_df_analysis = ... # Take some steps here to connect questionnaire data to dimensionally-reduced genotype data (i.e. UMAP and PCA coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae27e32-7ee8-4ede-bbc5-68505903c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clusters\n",
    "clustering = \"hdbscan_labels_min25_EPS0.3_hla_removed_ld_thinned.eigenvec_UMAP_PC25_NC3_NN10_MD0.001_euclidean_20220714_173646.txt\"\n",
    "clusters = np.loadtxt(os.path.join(cluster_dir,clustering))\n",
    "\n",
    "# Copy data frame and attach clusters\n",
    "geno_df_analysis = geno_aux_data.copy()\n",
    "geno_df_analysis[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae6772-e322-4a04-9256-c7a326b93b25",
   "metadata": {},
   "source": [
    "## Plotting PCA and UMAP with clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b33d4-5810-4ff3-a42d-d54717c17e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour palette\n",
    "pal = [\n",
    "    \"#238BC1\",\n",
    "    \"#203800\",\n",
    "    \"#32AC39\",\n",
    "    \"#E03D34\",\n",
    "    \"#A67FC9\",\n",
    "    \"#9F6A5E\",\n",
    "    \"#EB8FCD\",\n",
    "    \"#919191\",\n",
    "    \"#C8C62C\",\n",
    "    \"#610A24\",\n",
    "    \"#9c6146\",\n",
    "    \"#007352\",\n",
    "    \"#A22188\",\n",
    "    \"#FF9209\",\n",
    "    \"#00C8D8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94283a6-e36d-4c48-9ce3-010bb8548869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the embedding for visualization and the array of cluster labels to use\n",
    "viz_file = \"hla_removed_ld_thinned.eigenvec_UMAP_PC10_NC2_NN15_MD0.5_euclidean_20220714_174506.txt\" # original UMAP used for viz\n",
    "\n",
    "temp_proj = np.loadtxt(os.path.join(viz_dir, viz_file))\n",
    "cluster_array = geno_df_analysis.cluster.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b8996-c519-4d3d-930e-dd7dbe754d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA + clusters\n",
    "temp_proj = pca\n",
    "cluster_array = geno_df_analysis.cluster.values\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for cl in list(set(list(clusters))):\n",
    "    print(cl)\n",
    "    plt.plot(temp_proj[np.where(cluster_array==cl),0], \n",
    "             temp_proj[np.where(cluster_array==cl),1], \n",
    "                       '.', color = pal[int(cl)],\n",
    "            markersize=2.5, alpha=0.4)\n",
    "\n",
    "plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.rcParams.update({\"font.size\":22})\n",
    "\n",
    "fig_path = \"...\"\n",
    "plt.savefig(os.path.join(fig_path,\"cartagene_flagship_clusters_pca.png\"),dpi=300,\n",
    "           bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5957b5e-068a-440c-b087-5ad98a6599db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP + clusters\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for cl in geno_df_analysis[\"cluster\"].value_counts().index.values.tolist():\n",
    "    print(cl)\n",
    "    plt.plot(temp_proj[np.where(cluster_array==cl),0], \n",
    "             temp_proj[np.where(cluster_array==cl),1], \n",
    "                       '.', color = pal[int(cl)],\n",
    "            markersize=2.5, alpha=0.6)\n",
    "\n",
    "plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "plt.xlabel(\"UMAP1\")\n",
    "plt.ylabel(\"UMAP2\")\n",
    "plt.rcParams.update({\"font.size\":22})\n",
    "\n",
    "fig_path = \"...\"\n",
    "plt.savefig(os.path.join(fig_path,\"cartagene_flagship_clusters.png\"),dpi=300,\n",
    "           bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bb853-ff65-49fd-8f7f-9450ade68080",
   "metadata": {},
   "source": [
    "## Generate word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff812ca0-dd62-4759-aadc-4d7b51ed4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates word clouds for specified variables for each cluster.\n",
    "# Colours will match clusters\n",
    "fig_path = \"...\"\n",
    "cob_var = \"COUNTRY_BIRTH\"\n",
    "\n",
    "# Get the COBs from the cluster\n",
    "for cl in list(set(clusters)):    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    cluster_cobs = geno_df_analysis[geno_df_analysis[\"cluster\"]==cl][cob_var].values.tolist()\n",
    "    cluster_cobs = [c for c in cluster_cobs if str(c)!= \"nan\"]\n",
    "    \n",
    "    unique_str = (\" \").join(cluster_cobs)\n",
    "    wc = WordCloud(font_path=\"/usr/share/fonts/dejavu/DejaVuSansCondensed.ttf\",\n",
    "                   width=2000,\n",
    "                   height=2000,\n",
    "                   relative_scaling=0.8,\n",
    "                   prefer_horizontal=1,\n",
    "                   mode=\"RGBA\",\n",
    "                   background_color=pal[int(cl)]+\"11\",\n",
    "                   collocations=False,\n",
    "                   color_func=lambda *args, **kwargs: pal[int(cl)]).generate(unique_str)\n",
    "\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_color(pal[int(cl)])\n",
    "        ax.spines[axis].set_linewidth(3)\n",
    "\n",
    "    plt.imshow(wc)\n",
    "    \n",
    "    plt.savefig(os.path.join(fig_path,\"cartagene_wordclouds_\" + cob_var + str(int(cl)) + \".png\"),dpi=300,bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
